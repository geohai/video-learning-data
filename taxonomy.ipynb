{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to visualize the taxonomy of the egoexo4d dataset and convert annotations to different levels of annotations. This will lower the total number of annotations that need to be worked with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "CLI_OUTPUT_DIR = \"/local/juro4948/data/egoexo4d/egoexo\" # Replace with the full path to the --output_directory you pass to the cli\n",
    "VERSION = \"v1\"\n",
    "\n",
    "METADATA_PATH = os.path.join(CLI_OUTPUT_DIR, \"takes.json\")\n",
    "ANNOTATIONS_PATH = os.path.join(CLI_OUTPUT_DIR, \"annotations\")\n",
    "\n",
    "assert os.path.exists(METADATA_PATH), f\"Metadata doesn't exist at {METADATA_PATH}. Is the CLI_OUTPUT_DIR right? Do you satisfy the pre-requisites?\"\n",
    "assert os.path.exists(os.path.join(ANNOTATIONS_PATH, \"keystep_train.json\")), \"Annotation metadata doesn't exist. Did you download it with the CLI?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELEASE_DIR = \"/local/juro4948/data/egoexo4d/egoexo\"  # NOTE: changeme\n",
    "assert os.path.exists(RELEASE_DIR), \"change RELEASE_DIR to where you downloaded the dataset to\"\n",
    "\n",
    "egoexo = {\n",
    "    \"takes\": os.path.join(RELEASE_DIR, \"takes.json\"),\n",
    "    # \"takes_dropped\": os.path.join(RELEASE_DIR, \"takes_dropped.json\"),\n",
    "    \"captures\": os.path.join(RELEASE_DIR, \"captures.json\"),\n",
    "    \"physical_setting\": os.path.join(RELEASE_DIR, \"physical_setting.json\"),\n",
    "    \"participants\": os.path.join(RELEASE_DIR, \"participants.json\"),\n",
    "    \"visual_objects\": os.path.join(RELEASE_DIR, \"visual_objects.json\"),\n",
    "}\n",
    "\n",
    "TASK_ID_CAT = {\n",
    "    0: \"Unknown\",\n",
    "    1000: \"Cooking\",\n",
    "    2000: \"Health\",\n",
    "    4000: \"Bike Repair\",\n",
    "    5000: \"Music\",\n",
    "    6000: \"Basketball\",\n",
    "    7000: \"Rock Climbing\",\n",
    "    8000: \"Soccer\",\n",
    "    9000: \"Dance\",\n",
    "}\n",
    "\n",
    "for k, v in egoexo.items():\n",
    "    egoexo[k] = json.load(open(v))\n",
    "\n",
    "takes = egoexo[\"takes\"] \n",
    "captures = egoexo[\"captures\"]\n",
    "takes_by_uid = {x[\"take_uid\"]: x for x in takes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "636"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooking_takes = [take for take in takes if (take['parent_task_id'] == 1000)]\n",
    "len(cooking_takes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "egocentric = True\n",
    "use_downscaled = False\n",
    "\n",
    "\n",
    "#  TODO:  we should parse takes.json to get the ego_rgb_code for the rgb aria take. From visual inspection it seems that it's always 214-1, but we should be sure.\n",
    "if egocentric == True:\n",
    "    downsample_rate = 1 # this is the sampling factor - take every <rate> samples\n",
    "    camera = 'aria'\n",
    "    ego_rgb_code = '214-1' #\n",
    "    frame_rate = 30  # the raw frame rate ->  4k@60FPS (MP4) for GoPro devices and 1404x1404@30FPS (VRS) for Aria devices (https://docs.ego-exo4d-data.org/overview/#data)\n",
    "\n",
    "# TODO: fill in values here. Also, how to handle the 60fps vs 30fps issue? Could downsample cam by half\n",
    "elif egocentric == False:\n",
    "    camera = 'cam'\n",
    "    ego_rgb_code = '' \n",
    "    frame_rate = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training items: 671\n",
      "Length of training + val items: 852\n"
     ]
    }
   ],
   "source": [
    "# See raw annotations in this dictionary\n",
    "keystep_anns = json.load(open(os.path.join(ANNOTATIONS_PATH, \"keystep_train.json\")))\n",
    "keystep_anns_val = json.load(open(os.path.join(ANNOTATIONS_PATH, \"keystep_val.json\")))\n",
    "# Get taxonomy\n",
    "anns = keystep_anns[\"annotations\"]\n",
    "print(f'Length of training items: {len(anns)}')\n",
    "anns_test = keystep_anns_val[\"annotations\"]\n",
    "\n",
    "# Add anns_test to anns dictionary\n",
    "anns.update(anns_test)\n",
    "print(f'Length of training + val items: {len(anns)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n"
     ]
    }
   ],
   "source": [
    "# only get videos with keystep annotations\n",
    "cooking_uids = []\n",
    "for item in takes:\n",
    "    # check if this take is cooking\n",
    "    cat = item['parent_task_id']\n",
    "    if cat != 1000:\n",
    "        continue\n",
    "\n",
    "    # check if this take has annotations\n",
    "    has_annotations = False\n",
    "    for check_if_annotated in anns.keys():\n",
    "        if anns[check_if_annotated]['take_uid'] == item['take_uid']:\n",
    "            has_annotations = True\n",
    "            break\n",
    "    if not has_annotations:\n",
    "        continue\n",
    "    \n",
    "    cooking_uids.append(item['take_uid'])\n",
    "\n",
    "print(len(cooking_uids))\n",
    "#with open('egoexo4d/all_cooking_videos.txt', mode='wt', encoding='utf-8') as myfile:\n",
    "#     myfile.write('\\n'.join(cooking_uids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cooking Sushi Rolls',\n",
       " 'Cooking Tomato & Eggs',\n",
       " 'Making Chai Tea',\n",
       " 'Making Sesame-Ginger Asian Salad',\n",
       " 'Making Cucumber & Tomato Salad',\n",
       " 'Cooking Scrambled Eggs',\n",
       " 'Making Coffee latte',\n",
       " 'Cooking Pasta',\n",
       " 'Making Milk Tea',\n",
       " 'Cooking an Omelet',\n",
       " 'Cooking Noodles']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cooking_annotations = {}\n",
    "for uid in cooking_uids:\n",
    "    cooking_annotations[uid] = keystep_anns['annotations'][uid]\n",
    "\n",
    "# collect all cooking scenarios  \n",
    "cooking_scenarios = set()\n",
    "for uid in cooking_annotations.keys():\n",
    "    cooking_scenarios.add(cooking_annotations[uid]['scenario'])\n",
    "\n",
    "cooking_scenarios = list(cooking_scenarios)\n",
    "cooking_scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from treelib import Node, Tree\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "directory = \"Cooking Taxonomy Trees\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# filter cooking scenarios\n",
    "taxonomy_cooking = {}\n",
    "for scenario in cooking_scenarios:\n",
    "    taxonomy_cooking[scenario] = keystep_anns['taxonomy'][scenario] \n",
    "    # Create taxonomy tree\n",
    "    tree = Tree()\n",
    "    # Add nodes to the tree\n",
    "    for key, value in taxonomy_cooking[scenario].items():\n",
    "        parent_id = value['parent_id']\n",
    "        if parent_id is None:\n",
    "            tree.create_node(tag=value['name'], identifier=value['id'])\n",
    "        else:\n",
    "            tree.create_node(tag=value['name'], identifier=value['id'], parent=value['parent_id'])\n",
    "    # Save the tree to a text file in the specified directory\n",
    "    tree.save2file(os.path.join(directory, scenario + \" Taxonomy Tree.txt\"))\n",
    "\n",
    "# Concatenate all files into one\n",
    "with open(os.path.join(directory, \"All Taxonomy Trees.txt\"), \"w\") as outfile:\n",
    "    for scenario in cooking_scenarios:\n",
    "        with open(os.path.join(directory, scenario + \" Taxonomy Tree.txt\")) as infile:\n",
    "            outfile.write(infile.read())\n",
    "        outfile.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each line into its Level 2 Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(file_name, updated_taxonomy, input_directory, output_directory):\n",
    "    \n",
    "    # Read input file\n",
    "    with open(os.path.join(input_directory, file_name), 'r') as input_file:\n",
    "        lines = input_file.readlines()\n",
    "    \n",
    "    # Process each line\n",
    "    processed_lines = []\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()  # Remove leading/trailing white spaces\n",
    "        # Handle special line\n",
    "        if(line == \"action_start\"):\n",
    "            #print(\"Appended: action_start\")\n",
    "            processed_lines.append(line)\n",
    "        elif(line == \"action_end\"):\n",
    "            #print(\"Appended: action_end\")\n",
    "            processed_lines.append(line)\n",
    "        else: # For rest of lines\n",
    "            #print(\"\")\n",
    "            #print(f\"Unprocessed Line: \", line)\n",
    "            # Process line from annotation format to taxonomy format\n",
    "            newline = line.replace(\"_\", \" \")  # Replace underscores with spaces\n",
    "            words = newline.split()  # Split the string into words\n",
    "            words[0] = words[0].capitalize()  # Convert the first word to uppercase\n",
    "            newline = ' '.join(words)  # Join the words back together\n",
    "            #print(f\"Processed Line: \", newline)\n",
    "            #print(\"\")\n",
    "            #TODO: Get a better solution for handling taxonomy that share the same name but different ID\n",
    "            # Check if there is more than one item with the same value['name']\n",
    "            names = [value['name'] for key, value in updated_taxonomy.items()]\n",
    "            # If there is more than one item with the same value['name'], do not update taxonomy\n",
    "            if names.count(newline) > 1:\n",
    "                processed_line = newline\n",
    "                #print(f\"Multiple items share same name, using :\", processed_line)\n",
    "            else:\n",
    "                for key, value in updated_taxonomy.items():\n",
    "                    if value['name'] == newline:\n",
    "                        # Set processed line to desired taxonomy level\n",
    "                        processed_line = value['level_1_taxonomy_name']\n",
    "                        #break\n",
    "            \n",
    "            # Process line from taxonomy format to annotation format\n",
    "            processed_line = processed_line.lower()\n",
    "            processed_line = processed_line.replace(\" \", \"_\")\n",
    "            #print(f\"Appended: \",processed_line)\n",
    "            processed_lines.append(processed_line)\n",
    "    \n",
    "    # Write processed lines to output file\n",
    "    output_file_path = os.path.join(output_directory, file_name)\n",
    "    with open(output_file_path, 'w') as output_file:\n",
    "        for processed_line in processed_lines:\n",
    "            output_file.write(processed_line + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for uid in cooking_uids:\n",
    "    annotation = keystep_anns['annotations'][uid]\n",
    "    take_name = annotation['take_name']\n",
    "    scenario = annotation['scenario']\n",
    "    taxonomy = keystep_anns['taxonomy'][scenario]\n",
    "\n",
    "    #print(f\"Take Name: \",take_name)\n",
    "\n",
    "    # Initialize an empty dictionary to store Level 0 Taxonomy actions\n",
    "    level_0_taxonomy = {}\n",
    "    # Iterate over the taxonomy dictionary\n",
    "    for key, value in taxonomy.items():\n",
    "        # Check if the parent_id is 0\n",
    "        if value['parent_id'] == None:\n",
    "            # If yes, then add this action to the dictionary\n",
    "            level_0_taxonomy[key] = value\n",
    "\n",
    "    #print(f\"Level 0 Taxonomy: \",level_0_taxonomy)\n",
    "    \n",
    "    level_1_taxonomy = {}\n",
    "    # Iterate over the taxonomy dictionary\n",
    "    for key, value in taxonomy.items():\n",
    "        # Check if the parent_id is equal to any parent ID in level_0_taxonomy\n",
    "        if value['parent_id'] in [v['id'] for v in level_0_taxonomy.values()]:\n",
    "            # If yes, then add this action to the dictionary\n",
    "            level_1_taxonomy[key] = value\n",
    "            # Add higher_level taxonomies to dictionary\n",
    "            level_1_taxonomy[key]['level_0_taxonomy'] = value['parent_id']\n",
    "\n",
    "            # Add level_n_taxonomy_name to dictionary\n",
    "            level_1_taxonomy[key]['level_0_taxonomy_name'] = level_0_taxonomy[str(value['parent_id'])]['name']\n",
    "            level_1_taxonomy[key]['level_1_taxonomy_name'] = value['name']\n",
    "            # Add self as higher level level_n_taxonomy_name\n",
    "            level_1_taxonomy[key]['level_2_taxonomy_name'] = value['name']\n",
    "\n",
    "    #print(f\"Level 1 Taxonomy: \",level_1_taxonomy)\n",
    "\n",
    "    # Initialize an empty dictionary to store Level 2 Taxonomy actions\n",
    "    level_2_taxonomy = {}\n",
    "    # Iterate over the taxonomy dictionary\n",
    "    for key, value in taxonomy.items():\n",
    "        # Check if the parent_id is equal to any parent ID in level_1_taxonomy\n",
    "        if value['parent_id'] in [v['id'] for v in level_1_taxonomy.values()]:\n",
    "            # If yes, then add this action to the dictionary\n",
    "            level_2_taxonomy[key] = value\n",
    "            # Add higher_level taxonomies to dictionary\n",
    "            level_2_taxonomy[key]['level_1_taxonomy'] = value['parent_id']\n",
    "            # Get the parent_id of the level_1_taxonomy\n",
    "            level_1_parent_id = level_1_taxonomy[str(value['parent_id'])]['parent_id']\n",
    "            level_2_taxonomy[key]['level_0_taxonomy'] = level_1_parent_id\n",
    "\n",
    "            # Add level_n_taxonomy_name to dictionary\n",
    "            level_2_taxonomy[key]['level_0_taxonomy_name'] = level_0_taxonomy[str(level_1_parent_id)]['name']\n",
    "            level_2_taxonomy[key]['level_1_taxonomy_name'] = level_1_taxonomy[str(value['parent_id'])]['name']\n",
    "            level_2_taxonomy[key]['level_2_taxonomy_name'] = value['name']\n",
    "\n",
    "    #print(f\"Level 2 Taxonomy: \",level_2_taxonomy)\n",
    "\n",
    "    # Initialize an empty dictionary to store Level 3 Taxonomy actions\n",
    "    level_3_taxonomy = {}\n",
    "    # Iterate over the taxonomy dictionary\n",
    "    for key, value in taxonomy.items():\n",
    "        # Check if the parent_id is equal to any parent ID in level_2_taxonomy\n",
    "        if value['parent_id'] in [v['id'] for v in level_2_taxonomy.values()]:\n",
    "            # If yes, then add this action to the dictionary\n",
    "            level_3_taxonomy[key] = value\n",
    "            # Add higher_level taxonomies to dictionary\n",
    "            level_3_taxonomy[key]['level_2_taxonomy'] = value['parent_id']\n",
    "            # Get the parent_id of the level_2_taxonomy\n",
    "            level_2_parent_id = level_2_taxonomy[str(value['parent_id'])]['parent_id']\n",
    "            level_3_taxonomy[key]['level_1_taxonomy'] = level_2_parent_id\n",
    "            # Get the parent_id of the level_1_taxonomy\n",
    "            level_1_parent_id = level_1_taxonomy[str(level_2_parent_id)]['parent_id']\n",
    "            level_3_taxonomy[key]['level_0_taxonomy'] = level_1_parent_id\n",
    "\n",
    "            # Add level_n_taxonomy_name to dictionary\n",
    "            level_3_taxonomy[key]['level_0_taxonomy_name'] = level_0_taxonomy[str(level_1_parent_id)]['name']\n",
    "            level_3_taxonomy[key]['level_1_taxonomy_name'] = level_1_taxonomy[str(level_2_parent_id)]['name']\n",
    "            level_3_taxonomy[key]['level_2_taxonomy_name'] = level_2_taxonomy[str(value['parent_id'])]['name']\n",
    "            level_3_taxonomy[key]['level_3_taxonomy_name'] = value['name']\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "    #print(f\"Level 3 Taxonomy: \",level_3_taxonomy)\n",
    "\n",
    "    # Initialize an empty dictionary to store Level 4 Taxonomy actions\n",
    "    level_4_taxonomy = {}\n",
    "    # Iterate over the taxonomy dictionary\n",
    "    for key, value in taxonomy.items():\n",
    "        # Check if the parent_id is equal to any parent ID in level_3_taxonomy\n",
    "        if value['parent_id'] in [v['id'] for v in level_3_taxonomy.values()]:\n",
    "            # If yes, then add this action to the dictionary\n",
    "            level_4_taxonomy[key] = value\n",
    "            # Add higher_level taxonomies to dictionary\n",
    "            level_4_taxonomy[key]['level_3_taxonomy'] = value['parent_id']\n",
    "            # Get the parent_id of the level_3_taxonomy\n",
    "            level_3_parent_id = level_3_taxonomy[str(value['parent_id'])]['parent_id']\n",
    "            level_4_taxonomy[key]['level_2_taxonomy'] = level_3_parent_id\n",
    "            # Get the parent_id of the level_2_taxonomy\n",
    "            level_2_parent_id = level_2_taxonomy[str(level_3_parent_id)]['parent_id']\n",
    "            level_4_taxonomy[key]['level_1_taxonomy'] = level_2_parent_id\n",
    "            # Get the parent_id of the level_1_taxonomy\n",
    "            level_1_parent_id = level_1_taxonomy[str(level_2_parent_id)]['parent_id']\n",
    "            level_4_taxonomy[key]['level_0_taxonomy'] = level_1_parent_id\n",
    "            \n",
    "            # Add level_n_taxonomy_name to dictionary\n",
    "            level_4_taxonomy[key]['level_0_taxonomy_name'] = level_0_taxonomy[str(level_1_parent_id)]['name']\n",
    "            level_4_taxonomy[key]['level_1_taxonomy_name'] = level_1_taxonomy[str(level_2_parent_id)]['name']\n",
    "            level_4_taxonomy[key]['level_2_taxonomy_name'] = level_2_taxonomy[str(level_3_parent_id)]['name']\n",
    "            level_4_taxonomy[key]['level_3_taxonomy_name'] = level_3_taxonomy[str(value['parent_id'])]['name']\n",
    "            level_4_taxonomy[key]['level_4_taxonomy_name'] = value['name']\n",
    "\n",
    "\n",
    "    #print(f\"Level 4 Taxonomy: \",level_4_taxonomy)\n",
    "\n",
    "    # TODO: Make sure all possible Taxonomy levels are covered in the dataset we are using, i.e. do we need a level_5_taxonomy\n",
    "\n",
    "    # Add each level taxonomy to the updated taxonomy\n",
    "    updated_taxonomy = {}\n",
    "\n",
    "    updated_taxonomy.update(level_0_taxonomy)\n",
    "    updated_taxonomy.update(level_1_taxonomy)\n",
    "    updated_taxonomy.update(level_2_taxonomy)\n",
    "    updated_taxonomy.update(level_3_taxonomy)\n",
    "    updated_taxonomy.update(level_4_taxonomy)\n",
    "\n",
    "    #print(updated_taxonomy)\n",
    "\n",
    "\n",
    "    # Process file\n",
    "    file_name = take_name +\".txt\"\n",
    "    #print(\"File Name: \", file_name)\n",
    "    input_directory = '/local/juro4948/data/egoexo4d/preprocessed/annotations/gravit-groundTruth/'\n",
    "    output_directory = '/local/juro4948/data/egoexo4d/preprocessed/annotations/gravit-groundTruth-level1-taxonomy/'\n",
    "    #process_file(file_name, updated_taxonomy, input_directory, output_directory)\n",
    "    #break # Breaking after processing first file for testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is used to find the number of unique classes in the annotations. This parameter can be updated in \n",
    "configs/egoexo/egoexo_ft.yaml\n",
    "num_classes: []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def count_unique_lines(directory):\n",
    "    unique_lines = set()\n",
    "    for filename in glob.glob(os.path.join(directory, '*')):\n",
    "        with open(filename, 'r') as f:\n",
    "            lines = [line.strip() for line in f]\n",
    "            unique_lines.update(lines)\n",
    "    return len(unique_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of classes is: 169\n",
      "Update num_classes in configs/egoexo/egoexo_ft.yaml with this number\n"
     ]
    }
   ],
   "source": [
    "directory = '/local/juro4948/data/egoexo4d/preprocessed/annotations/gravit-groundTruth-level1-taxonomy/'\n",
    "print(f\"The total number of classes is: {count_unique_lines(directory)}\")\n",
    "print(f\"Update num_classes in configs/egoexo/egoexo_ft.yaml with this number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
