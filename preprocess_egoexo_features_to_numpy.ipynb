{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference from https://github.com/facebookresearch/Ego4d/blob/main/ego4d/research/dataset.py#L13\n",
    "\n",
    "def save_ego4d_features_to_hdf5(video_uids: List[str], feature_dir: str, out_path: str):\n",
    "    \"\"\"\n",
    "    Use this function to preprocess Ego4D features into a HDF5 file with h5py\n",
    "    \"\"\"\n",
    "    with h5py.File(out_path, \"w\") as out_f:\n",
    "        for uid in tqdm(video_uids, desc=\"video_uid\", leave=True):\n",
    "            feature_path = os.path.join(feature_dir, f\"{uid}.pt\")\n",
    "            fv = torch.load(feature_path)\n",
    "            out_f.create_dataset(uid, data=fv.numpy())\n",
    "\n",
    "\n",
    "def save_ego4d_features_to_numpy(video_uids: List[str], feature_dir: str, out_dir: str):\n",
    "    \"\"\"\n",
    "    Use this function to preprocess EgoExo4D features into individual numpy files\n",
    "    \"\"\"\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    for uid in video_uids:\n",
    "        feature_path = os.path.join(feature_dir, f\"{uid}.pt\")\n",
    "        fv = torch.load(feature_path)\n",
    "        fv_numpy = fv.numpy()\n",
    "        fv_numpy_squeezed = np.squeeze(fv_numpy, axis=1)\n",
    "        np.save(os.path.join(out_dir, f\"{uid}.npy\"), fv_numpy_squeezed)\n",
    "\n",
    "# modify to use list of labels\n",
    "class LabelledFeatureDset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A simple utility class to load features associated with labels. The input this\n",
    "    method requires is as follows:\n",
    "        1. `feature_hdf5_path`: the features transposed to a HDF5 file.\n",
    "            See `save_ego4d_features_to_hdf5`\n",
    "        2. `uid_label_path`: a list of (uid, path_to_labels). `path_to_labels` is a\n",
    "            path to a file containing labels for the uid.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        feature_hdf5_path: str,\n",
    "        uid_label_pairs: List[Tuple[str, Any]],\n",
    "    ):\n",
    "        self.uid_label_pairs = uid_label_pairs\n",
    "        self.features = h5py.File(feature_hdf5_path)\n",
    "\n",
    "        # frame_index = \n",
    "        # seq = [Image.open(os.path.join(vpath, path_list[i])).convert('RGB') for i in frame_index]\n",
    "        # vid = vlabel[frame_index]\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.uid_label_pairs)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        uid, label = self.uid_label_pairs[idx]\n",
    "        # feat = self.aggr_function(self.features[uid], label)\n",
    "        return feat, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3045b732a8e4b8796027d83e7cfba19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "video_uid:   0%|          | 0/2880 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uids = ['0a6a26fa-cbbc-4843-bf28-9f799119a4bc_aria_rgb', '00a6dd13-d5b0-4743-b252-ed61e61f1d49_aria06_rgb']\n",
    "feature_dir = 'egoexo4d/egoexo/features/omnivore_video/'\n",
    "files = os.listdir(feature_dir)\n",
    "uids = [fn.split('.')[0] for fn in files]\n",
    "\n",
    "# save_ego4d_features_to_hdf5(video_uids=uids, feature_dir=feature_dir, out_path='egoexo4d/preprocessed_old/egoexo4d_features.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to annotations\n",
    "label_dir = 'egoexo4d/egoexo/annotations/gravit-groundTruth' # these are at 30FPS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([202, 1, 1536])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(feature_dir + '0a6a26fa-cbbc-4843-bf28-9f799119a4bc_aria_rgb.pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([202, 1, 1536])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(feature_dir + '0a6a26fa-cbbc-4843-bf28-9f799119a4bc_cam01_0.pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1245, 1, 1536])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(feature_dir + '00a6dd13-d5b0-4743-b252-ed61e61f1d49_aria06_rgb.pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1245, 1, 1536])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(feature_dir + '00a6dd13-d5b0-4743-b252-ed61e61f1d49_cam01_0.pt').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension of Omnivore Swin-L's features for EgoExo4D: [n_frames, 1, n_features]\n",
    "Seems like all GoPro streams were downsampled to 30 FPS before feature extraction so labels are equivalent between aria and gopro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gravit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
